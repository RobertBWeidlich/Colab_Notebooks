{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5i2DbD5tNh0FAXyItise8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobertBWeidlich/Colab_Notebooks/blob/main/CorpusAnalysisWSpaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus Analysis with spaCy\n",
        "#\n",
        "# Fri Dec  1 19:53:39 EST 2023\n",
        "#\n",
        "# Megan S. Kane ORCID id icon\n",
        "#\n",
        "# This lesson demonstrates how to use the Python library spaCy for analysis of\n",
        "# large collections of texts. This lesson details the process of using spaCy\n",
        "# to enrich a corpus via lemmatization, part-of-speech tagging, dependency\n",
        "# parsing, and named entity recognition. Readers will learn how the\n",
        "# linguistic annotations produced by spaCy can be analyzed to help\n",
        "# researchers explore meaningful trends in language patterns across a set\n",
        "# of texts.\n",
        "#\n",
        "# https://programminghistorian.org/en/lessons/corpus-analysis-with-spacy\n",
        "#"
      ],
      "metadata": {
        "id": "5Yh7Fs62jb3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bgg_s4ubjkiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qq00AA-O8Apn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import os\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "pdHvXijl3kfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXMXEWHi-F52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. upload files from local system - select manually\n",
        "import json\n",
        "\n",
        "uploaded_files = files.upload()\n",
        "for fn in uploaded_files.keys():\n",
        "  print(f\"fn: \\\"{fn}\\\"\")\n",
        "  print(f\"len: {len(uploaded_files[fn])}\")\n"
      ],
      "metadata": {
        "id": "EDDv4LCpjvPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "\n",
        "def clean_cn_rss_json_file(filename: str) -> bool:\n",
        "  # data files have comment lines (first line is '#' character), which\n",
        "  # is not standard JSON, so they have to be removed.\n",
        "  import os\n",
        "  import shutil\n",
        "\n",
        "  # 1. move cn_rss_proc-20230817.json to cn_rss_proc-20230817.json-orig\n",
        "  orig_filename = f\"{filename}-orig\"\n",
        "  #print(filename)\n",
        "  #print(orig_filename)\n",
        "  print(f\"moving \\\"{filename}\\\" --> \\\"{orig_filename}\\\"\")\n",
        "  shutil.move(filename, orig_filename)\n",
        "\n",
        "  # 2. cn_rss_proc-20230817.json-orig -> [filter] -> cn_rss_proc-20230817.json\n",
        "  with open(orig_filename) as ifp:\n",
        "    with open(filename, \"w\") as ofp:\n",
        "      # 2a. iterate line by line\n",
        "      for line in ifp:\n",
        "        # note: retaining original new line at end of string\n",
        "        #print(f\"len: {len(line)}\")\n",
        "        #print(f\">>>{line}<<<\")\n",
        "        if (len(line) > 0) and (line[0] != '#'):\n",
        "          # note - \" #\" line not a comment, \"# \" IS a comment\n",
        "          #print(\"printing to output\")\n",
        "          ofp.write(line)\n",
        "\n",
        "  # 3. delete cn_rss_proc-20230817.json-orig??\n",
        "\n",
        "###clean_cn_rss_json_file(\"cn_rss_proc-20230817.json\")\n",
        "##clean_cn_rss_json_file(\"c:\\\\\\cn_rss_proc-20231105.json\")\n",
        "##clean_cn_rss_json_file(\"cn_rss_proc-20231105.json\")\n",
        "#clean_cn_rss_json_file(\"cn_rss_proc-20230817.json\")"
      ],
      "metadata": {
        "id": "BsuORWNd8uzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Convert files to NDJSON, by\n",
        "#    a. clean non-JSON comments from data files\n",
        "#    b. compress each JSON record to single lines\n",
        "for fn in uploaded_files.keys():\n",
        "  print(f\"fn: \\\"{fn}\\\"\")\n",
        "  print(f\"len: {len(uploaded_files[fn])}\")\n",
        "  clean_cn_rss_json_file(fn)"
      ],
      "metadata": {
        "id": "re334MaG-8XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print list of cleaned, uploaded files\n",
        "print(type(uploaded_files))\n",
        "for key in uploaded_files:\n",
        "  print(f\"  {key}\")\n",
        "print(type(list(uploaded_files.keys())))\n",
        "first_file = list(uploaded_files.keys())[0]\n",
        "first_file = list(uploaded_files.keys())[0]\n",
        "print(f\"first_file: \\\"{first_file}\\\"\")\n",
        "\n",
        "# load in pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(first_file, lines=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "QZDZ0nfs_Zxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_json('{\"a\":1,\\n\"b\":2}\\n{\"a\":3,\\n\"b\":4}', lines=True)"
      ],
      "metadata": {
        "id": "o1a_FPDuqttN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fn1GNmDa0ZPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}